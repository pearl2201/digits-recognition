{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\",one_hot = True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_steps = 200\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "num_input = 784\n",
    "num_classes = 10\n",
    "dropout = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy data\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train,(-1,28,28,1))\n",
    "x_test = np.reshape(x_test,(-1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "55000/55000 [==============================] - 447s 8ms/step - loss: 2.0241 - acc: 0.3004\n",
      "Epoch 2/4\n",
      "55000/55000 [==============================] - 476s 9ms/step - loss: 0.5535 - acc: 0.8230\n",
      "Epoch 3/4\n",
      "55000/55000 [==============================] - 469s 9ms/step - loss: 0.3221 - acc: 0.8991\n",
      "Epoch 4/4\n",
      "55000/55000 [==============================] - 472s 9ms/step - loss: 0.2500 - acc: 0.9220\n",
      "10000/10000 [==============================] - 28s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=4)\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "model.save(\"digits.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# define the checkpoint\n",
    "filepath = \"digits.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 379s 7ms/step - loss: 0.2057 - acc: 0.9365\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.20573, saving model to digits.h5\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 358s 7ms/step - loss: 0.1805 - acc: 0.9434\n",
      "\n",
      "Epoch 00002: loss improved from 0.20573 to 0.18050, saving model to digits.h5\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 344s 6ms/step - loss: 0.1637 - acc: 0.9488\n",
      "\n",
      "Epoch 00003: loss improved from 0.18050 to 0.16367, saving model to digits.h5\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 339s 6ms/step - loss: 0.1462 - acc: 0.9542\n",
      "\n",
      "Epoch 00004: loss improved from 0.16367 to 0.14624, saving model to digits.h5\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 350s 6ms/step - loss: 0.1380 - acc: 0.9565\n",
      "\n",
      "Epoch 00005: loss improved from 0.14624 to 0.13798, saving model to digits.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22886bd1eb8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(x_train, y_train, epochs=5, batch_size=batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29184/55000 [==============>...............] - ETA: 3:06 - loss: 0.1329 - acc: 0.9579"
     ]
    }
   ],
   "source": [
    "new_model.fit(x_train, y_train, epochs=10, batch_size=batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
